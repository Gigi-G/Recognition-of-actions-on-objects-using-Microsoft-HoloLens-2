{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b57ba0a3",
   "metadata": {
    "id": "b57ba0a3"
   },
   "source": [
    "# LSTM - 2.0\n",
    "\n",
    "Una seconda implementazione di LSTM senza sovrapposizione delle finestre temporali."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d826350",
   "metadata": {
    "id": "2d826350"
   },
   "source": [
    "## Caricamento del dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cac63e0",
   "metadata": {
    "id": "5cac63e0"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, accuracy_score\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from scipy.stats import mode\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "main_folder = \"../data\"\n",
    "\n",
    "folder = \"./runs/LSTM_1\"\n",
    "\n",
    "try:\n",
    "    shutil.rmtree(folder, ignore_errors=True)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    os.mkdir(folder)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "writer = SummaryWriter(folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbaa788",
   "metadata": {
    "id": "acbaa788"
   },
   "source": [
    "## Train - Validation - Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ec9a06",
   "metadata": {
    "id": "24ec9a06"
   },
   "outputs": [],
   "source": [
    "LABELS = [\n",
    "    \"No_action\",\n",
    "    \"Prendi\",\n",
    "    \"Rilascia\",\n",
    "    \"Premi\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8affb0f7",
   "metadata": {
    "id": "8affb0f7"
   },
   "outputs": [],
   "source": [
    "class2idx = {\n",
    "    \"No_action\": 0,\n",
    "    \"Prendi\": 1,\n",
    "    \"Rilascia\": 2,\n",
    "    \"Premi\": 3\n",
    "}\n",
    "\n",
    "idx2class = {v: k for k, v in class2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ed37c9",
   "metadata": {
    "id": "49ed37c9"
   },
   "outputs": [],
   "source": [
    "def join_csv(folder_set, filename):\n",
    "    csv:list = []\n",
    "\n",
    "    for file in glob.glob(folder_set + \"/*.csv\"):\n",
    "        csv.append(file)\n",
    "\n",
    "    columns:bool = True\n",
    "    with open(filename, \"w\") as f:\n",
    "        for fcsv in csv:\n",
    "            with open(fcsv, \"r\") as fc:\n",
    "                if columns:\n",
    "                    f.writelines(fc.readlines())\n",
    "                    columns = False\n",
    "                fc.readline()\n",
    "                f.writelines(fc.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148e392d",
   "metadata": {
    "id": "148e392d"
   },
   "outputs": [],
   "source": [
    "def create_set(folder_set):\n",
    "    csv:list = []\n",
    "    for file in glob.glob(folder_set + \"/*.csv\"):\n",
    "        csv.append(file)\n",
    "    data = []\n",
    "    target = []\n",
    "    for fcsv in csv:\n",
    "        data_video = pd.read_csv(fcsv, usecols = [i for i in range(156)]).to_numpy()\n",
    "        target_video = pd.read_csv(fcsv, usecols = [\"TARGET\"])\n",
    "        target_video[\"TARGET\"].replace(class2idx, inplace=True)\n",
    "        data.append(data_video)\n",
    "        target.append(target_video.to_numpy())\n",
    "    return (np.array(data, dtype=object), np.array(target, dtype=object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-znJCwBvJBZK",
   "metadata": {
    "id": "-znJCwBvJBZK"
   },
   "outputs": [],
   "source": [
    "folder_set = [[main_folder + \"/train_set\", main_folder + \"/train.csv\"], [main_folder + \"/test_set\", main_folder + \"/test.csv\"], [main_folder + \"/val_set\", main_folder + \"/val.csv\"]]\n",
    "\n",
    "train_array, train_label_array = create_set(folder_set[0][0])\n",
    "test_array, test_label_array = create_set(folder_set[1][0])\n",
    "val_array, val_label_array = create_set(folder_set[2][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68198fb8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "68198fb8",
    "outputId": "e9640b49-829d-4ef4-b958-55075cedc936"
   },
   "outputs": [],
   "source": [
    "print(train_array.shape, train_label_array.shape, test_array.shape, test_label_array.shape, val_array.shape, val_label_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd772ab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3cd772ab",
    "outputId": "4bf6859e-63c1-4ff9-c140-d9fd88213f92"
   },
   "outputs": [],
   "source": [
    "for elem, label in zip(train_array, train_label_array):\n",
    "    print(elem.shape, label.shape)\n",
    "    print(type(elem), type(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eca6d5f",
   "metadata": {
    "id": "3eca6d5f"
   },
   "outputs": [],
   "source": [
    "folder_set = [[main_folder + \"/train_set\", main_folder + \"/train.csv\"], [main_folder + \"/test_set\", main_folder + \"/test.csv\"], [main_folder + \"/val_set\", main_folder + \"/val.csv\"]]\n",
    "\n",
    "for f_set, filename in folder_set:\n",
    "    join_csv(f_set, filename)\n",
    "    \n",
    "train = pd.read_csv(main_folder + \"/train.csv\")\n",
    "test = pd.read_csv(main_folder + \"/test.csv\")\n",
    "val = pd.read_csv(main_folder + \"/val.csv\")\n",
    "\n",
    "train['TARGET'].replace(class2idx, inplace=True)\n",
    "test['TARGET'].replace(class2idx, inplace=True)\n",
    "val['TARGET'].replace(class2idx, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a38725f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "id": "7a38725f",
    "outputId": "576ec654-0c80-4a43-e749-9665cba86ffb"
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a27cc3b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "id": "4a27cc3b",
    "outputId": "26769409-b8a6-4c23-ef1d-ce1c9c424623"
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7522085c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "id": "7522085c",
    "outputId": "b30e7f07-0dbc-42bd-bd55-2eccff362f97"
   },
   "outputs": [],
   "source": [
    "val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e196b6c0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e196b6c0",
    "outputId": "373d78af-7d16-4edb-ab99-23f4ac3f093c"
   },
   "outputs": [],
   "source": [
    "print(train.shape[0], test.shape[0], val.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4ea305",
   "metadata": {
    "id": "da4ea305"
   },
   "source": [
    "Si separano le colonne delle features dall'etichetta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c6d06b",
   "metadata": {
    "id": "d1c6d06b"
   },
   "outputs": [],
   "source": [
    "train_label = train[\"TARGET\"]\n",
    "test_label = test[\"TARGET\"]\n",
    "val_label = val[\"TARGET\"]\n",
    "\n",
    "del train[\"TARGET\"]\n",
    "del test[\"TARGET\"]\n",
    "del val[\"TARGET\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "owUiLKf4H9jh",
   "metadata": {
    "id": "owUiLKf4H9jh"
   },
   "source": [
    "## Visualizzazione della distribuzione delle classi in Train, Val e Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NvPdymyAH07E",
   "metadata": {
    "id": "NvPdymyAH07E"
   },
   "outputs": [],
   "source": [
    "def get_class_distribution(obj):\n",
    "    count_dict = {\n",
    "        \"No_action\": 0,\n",
    "        \"Prendi\": 0,\n",
    "        \"Rilascia\": 0,\n",
    "        \"Premi\": 0,\n",
    "    }\n",
    "    \n",
    "    for i in obj:\n",
    "        if i == 0: \n",
    "            count_dict['No_action'] += 1\n",
    "        elif i == 1: \n",
    "            count_dict['Prendi'] += 1\n",
    "        elif i == 2: \n",
    "            count_dict['Rilascia'] += 1\n",
    "        elif i == 3: \n",
    "            count_dict['Premi'] += 1            \n",
    "        else:\n",
    "            print(\"Check classes.\")\n",
    "            \n",
    "    return count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mdj_1catIJPD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "mdj_1catIJPD",
    "outputId": "d31f7a41-4822-4042-b982-8f0450236b4a"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(25,7))\n",
    "# Train\n",
    "sns.barplot(data = pd.DataFrame.from_dict([get_class_distribution(train_label)]).melt(), x = \"variable\", y=\"value\", hue=\"variable\",  ax=axes[0]).set_title('Class Distribution in Train Set')\n",
    "# Validation\n",
    "sns.barplot(data = pd.DataFrame.from_dict([get_class_distribution(val_label)]).melt(), x = \"variable\", y=\"value\", hue=\"variable\",  ax=axes[1]).set_title('Class Distribution in Val Set')\n",
    "# Test\n",
    "sns.barplot(data = pd.DataFrame.from_dict([get_class_distribution(test_label)]).melt(), x = \"variable\", y=\"value\", hue=\"variable\",  ax=axes[2]).set_title('Class Distribution in Test Set')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i3SiYeWKKX9P",
   "metadata": {
    "id": "i3SiYeWKKX9P"
   },
   "source": [
    "## Weighted Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fGJur35nKc4Y",
   "metadata": {
    "id": "fGJur35nKc4Y"
   },
   "source": [
    "Poiché c'è uno squilibrio di classe, utilizziamo la suddivisione stratificata per creare i nostri set di train, convalida e test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fef0ed3",
   "metadata": {
    "id": "4fef0ed3"
   },
   "outputs": [],
   "source": [
    "class ClassifierDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0126e325",
   "metadata": {
    "id": "0126e325"
   },
   "outputs": [],
   "source": [
    "def create_dataset(dataset, target, window_size):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - window_size):\n",
    "        dataX.append(dataset[i:(i + window_size)])\n",
    "        dataY.append(target[i:(i + window_size + 1)].values[0])\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679b12e8",
   "metadata": {
    "id": "679b12e8"
   },
   "outputs": [],
   "source": [
    "train_X, train_Y = create_dataset(train, train_label, 1)\n",
    "train_dataset_w = ClassifierDataset(torch.from_numpy(train_X).float(), torch.from_numpy(train_Y).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XAC-pLjfKlRB",
   "metadata": {
    "id": "XAC-pLjfKlRB"
   },
   "outputs": [],
   "source": [
    "target_list = []\n",
    "\n",
    "for _, t in train_dataset_w:\n",
    "    target_list.append(t)\n",
    "    \n",
    "target_list = torch.tensor(target_list)\n",
    "target_list = target_list[torch.randperm(len(target_list))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zSWgB6_kLDcB",
   "metadata": {
    "id": "zSWgB6_kLDcB"
   },
   "source": [
    "Quindi, otteniamo il conteggio di tutte le classi nel nostro set di allenamento.  Usiamo il reciproco di ogni conteggio per ottenere il suo peso.  Ora che abbiamo calcolato i pesi per ogni classe, possiamo procedere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AfYqQv22LFiY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AfYqQv22LFiY",
    "outputId": "58df10ea-7695-434e-c814-ad4b8cfa942a"
   },
   "outputs": [],
   "source": [
    "class_count = [i for i in get_class_distribution(train_label).values()]\n",
    "class_weights = 1./torch.tensor(class_count, dtype=torch.float) \n",
    "\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kTcnQd-qLm_E",
   "metadata": {
    "id": "kTcnQd-qLm_E"
   },
   "source": [
    "WeightedRandomSampler prevede un peso per ogni campione.  Lo usiamo come segue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_k5ysLm-LRoX",
   "metadata": {
    "id": "_k5ysLm-LRoX"
   },
   "outputs": [],
   "source": [
    "class_weights_all = class_weights[target_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jzKuSiX2LuMs",
   "metadata": {
    "id": "jzKuSiX2LuMs"
   },
   "source": [
    "Infine, inizializziamo il nostro WeightedRandomSampler.  Lo chiameremo nel nostro dataloader in seguito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0Kcco4ucL3j7",
   "metadata": {
    "id": "0Kcco4ucL3j7"
   },
   "outputs": [],
   "source": [
    "weighted_sampler = WeightedRandomSampler(\n",
    "    weights=class_weights_all,\n",
    "    num_samples=len(class_weights_all),\n",
    "    replacement=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e449aca9",
   "metadata": {
    "id": "e449aca9"
   },
   "source": [
    "## Parametri del modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b569e3d",
   "metadata": {
    "id": "9b569e3d"
   },
   "outputs": [],
   "source": [
    "class ClassifierDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, array, label, index_data, window):\n",
    "        self.index_data = index_data\n",
    "        self.array = array\n",
    "        self.label = label\n",
    "        self.window = window\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        file_index = self.index_data[index][0].tolist()\n",
    "        i = self.index_data[index][1]\n",
    "        j = self.index_data[index][2]\n",
    "        if i == j:\n",
    "            x_data = [self.array[file_index][i]] * self.window\n",
    "            y_data = self.label[file_index][i]\n",
    "            X = torch.from_numpy(np.array(x_data).astype(float)).float()\n",
    "            Y = torch.from_numpy(np.array([y_data]).astype(int)).long()\n",
    "            return X, Y\n",
    "        elif j-i < self.window-1:\n",
    "            x_data = [self.array[file_index][i]] * (self.window-j)\n",
    "            x_data.extend(self.array[file_index][(i+1):(j+1)])\n",
    "            x_data = np.array(x_data).astype(float)\n",
    "        else:\n",
    "            x_data = self.array[file_index][i:(j+1)]\n",
    "            k = j-1\n",
    "            while len(x_data) > self.window:\n",
    "                x_data = self.array[file_index][i:(k+1)]\n",
    "                k -= 1\n",
    "        X = torch.from_numpy(x_data).float()\n",
    "        y_data = self.label[file_index][i:(j+1)]\n",
    "        y_mode = mode(y_data)[0][0]\n",
    "        Y = torch.from_numpy(np.array([y_mode])).long()\n",
    "        return X, Y\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.index_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f82fcc7",
   "metadata": {
    "id": "9f82fcc7"
   },
   "outputs": [],
   "source": [
    "def create_dataset(array_data, label_data, window):\n",
    "    X = []\n",
    "    files_num = len(array_data)\n",
    "    for index, array, label in zip(range(files_num), array_data, label_data):\n",
    "        l = array.shape[0]\n",
    "        i = 0\n",
    "        while l - i >= window:\n",
    "            j = i + window\n",
    "            index_window = np.array([index, i, j]).astype(int)\n",
    "            X.append(index_window)\n",
    "            i += window\n",
    "        if i < l:\n",
    "            w = l - i\n",
    "            i = i - window\n",
    "            i = i + w\n",
    "            j = i + window\n",
    "            index_window = np.array([index, i, j]).astype(int)\n",
    "            X.append(index_window)\n",
    "    X_data = torch.from_numpy(np.array(X).astype(int))\n",
    "    return ClassifierDataset(array_data, label_data, X_data, window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172d3e3f",
   "metadata": {
    "id": "172d3e3f"
   },
   "outputs": [],
   "source": [
    "def create_dataset2(array_data, label_data, window):\n",
    "    X = []\n",
    "    files_num = len(array_data)\n",
    "    for index, array, label in zip(range(files_num), array_data, label_data):\n",
    "        l = array.shape[0]\n",
    "        i = -1\n",
    "        w = [0] * window\n",
    "        while i < l:\n",
    "            i += 1 \n",
    "            w.pop(0)\n",
    "            w.append(i)\n",
    "            index_window = np.array([index, w[0], i]).astype(int)\n",
    "            X.append(index_window)\n",
    "    X_data = torch.from_numpy(np.array(X).astype(int))\n",
    "    return ClassifierDataset(array_data, label_data, X_data, window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404be4ab",
   "metadata": {
    "id": "404be4ab"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 200\n",
    "window = 3\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 0.05\n",
    "NUM_LAYER = 1\n",
    "NUM_HIDDEN = 192\n",
    "NUM_FEATURES = 156\n",
    "NUM_CLASSES = 4\n",
    "index_name = 51\n",
    "model_name = \"000\" + str(index_name) + \"_mymodel.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383c55f2",
   "metadata": {
    "id": "383c55f2"
   },
   "outputs": [],
   "source": [
    "train_dataset = create_dataset(train_array, train_label_array, window)\n",
    "test_dataset = create_dataset2(test_array, test_label_array, window)\n",
    "val_dataset = create_dataset2(val_array, val_label_array, window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f0cb16",
   "metadata": {
    "id": "95f0cb16"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xIhZwk2cXc4i",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xIhZwk2cXc4i",
    "outputId": "55b78191-0073-4e6b-da26-0ff11756a345"
   },
   "outputs": [],
   "source": [
    "print(train_dataset.index_data.shape)\n",
    "print(len(train_dataset))\n",
    "print(test_dataset.index_data.shape)\n",
    "print(len(test_dataset))\n",
    "print(val_dataset.index_data.shape)\n",
    "print(len(val_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e5701a",
   "metadata": {
    "id": "20e5701a"
   },
   "source": [
    "## Rete Neurale LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EGVAIQMIS685",
   "metadata": {
    "id": "EGVAIQMIS685"
   },
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, window, output_size, hidden_layer_size, num_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_layer_size\n",
    "        self.output_size = output_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size, num_layers)\n",
    "        self.regressor = nn.Linear(hidden_layer_size, output_size)\n",
    "        \n",
    "    def forward(self, x, hidden=None):\n",
    "        if hidden is not None:\n",
    "            h0 = hidden[0]\n",
    "            c0 = hidden [1]\n",
    "        else:\n",
    "            h0 = torch.zeros(self.num_layers, x.size()[0], self.hidden_size).to(device)\n",
    "            c0 = torch.zeros(self.num_layers, x.size()[0], self.hidden_size).to(device)\n",
    "        e = x.view(x.size(1), x.size(0), x.size(2))\n",
    "        h, hn = self.lstm(e, (h0, c0))\n",
    "        h = h.view(h.size(1), h.size(0), h.size(2))\n",
    "        h = h[:,-1,:]\n",
    "        h = self.regressor(h)\n",
    "        return h, hn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e18779",
   "metadata": {
    "id": "78e18779"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8781ca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9a8781ca",
    "outputId": "5fe5e93a-1e0d-4afc-90f5-db8f2415eb0e"
   },
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62349e74",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "62349e74",
    "outputId": "85fe583c-0834-48d1-f9f0-65136e6a6d0a"
   },
   "outputs": [],
   "source": [
    "model = LSTM(input_size=NUM_FEATURES, window=window, output_size=NUM_CLASSES, hidden_layer_size=NUM_HIDDEN, num_layers=NUM_LAYER)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930e16a8",
   "metadata": {
    "id": "930e16a8"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38b5ea5",
   "metadata": {
    "id": "d38b5ea5"
   },
   "source": [
    "Prima di iniziare il nostro addestramento, definiamo una funzione per calcolare la precisione per epoca."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77daf61",
   "metadata": {
    "id": "e77daf61"
   },
   "source": [
    "Questa funzione accetta y_pred e y_test come argomenti di input.  Quindi applichiamo log_softmax a y_pred ed estraiamo la classe che ha una probabilità maggiore."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0aa302",
   "metadata": {
    "id": "ab0aa302"
   },
   "source": [
    "Successivamente, confrontiamo le classi previste e le classi effettive per calcolare l'accuratezza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e865bfb",
   "metadata": {
    "id": "1e865bfb"
   },
   "outputs": [],
   "source": [
    "def categoryFromOutput(output):\n",
    "    top_n, top_i = output.topk(1)\n",
    "    category_i = top_i[0].item()\n",
    "    return LABELS[category_i], category_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6beef30c",
   "metadata": {
    "id": "6beef30c"
   },
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y_true):\n",
    "    return accuracy_score(y_true, y_pred) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167ce754",
   "metadata": {
    "id": "167ce754"
   },
   "outputs": [],
   "source": [
    "def f1_s(y_pred, y_true):\n",
    "    return f1_score(y_true, y_pred, average=None, zero_division=1, labels=[0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcfc05e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dfcfc05e",
    "outputId": "f747f3b7-c32b-4a43-bcde-07f720726168"
   },
   "outputs": [],
   "source": [
    "print('test_data_size:',test_dataset.index_data.size())\n",
    "print('test_label_size:',test_dataset.index_data.size())\n",
    "n_data_size_test = test_dataset.index_data.size()[0]\n",
    "print('n_data_size_test:',n_data_size_test)\n",
    "\n",
    "print('train_data_size:',train_dataset.index_data.size())\n",
    "print('train_label_size:',train_dataset.index_data.size())\n",
    "n_data_size_train = train_dataset.index_data.size()[0]\n",
    "print('n_data_size_train:',n_data_size_train)\n",
    "\n",
    "print('val_data_size:',val_dataset.index_data.size())\n",
    "print('val_label_size:',val_dataset.index_data.size())\n",
    "n_data_size_val = val_dataset.index_data.size()[0]\n",
    "print('n_data_size_val:',n_data_size_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a2c253",
   "metadata": {
    "id": "85a2c253"
   },
   "source": [
    "Definiremo anche 2 dizionari che memorizzeranno l'accuratezza/epoca e la perdita/epoca sia per il treno che per i set di convalida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c907075c",
   "metadata": {
    "id": "c907075c"
   },
   "outputs": [],
   "source": [
    "accuracy_stats = {\n",
    "    'train': [],\n",
    "    \"val\": []\n",
    "}\n",
    "\n",
    "loss_stats = {\n",
    "    'train': [],\n",
    "    \"val\": []\n",
    "}\n",
    "\n",
    "f1_score_No_action = {\n",
    "    'train': [],\n",
    "    \"val\": []\n",
    "}\n",
    "\n",
    "f1_score_Prendi = {\n",
    "    'train': [],\n",
    "    \"val\": []\n",
    "}\n",
    "\n",
    "f1_score_Rilascia = {\n",
    "    'train': [],\n",
    "    \"val\": []\n",
    "}\n",
    "\n",
    "f1_score_Premi = {\n",
    "    'train': [],\n",
    "    \"val\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3819558",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103,
     "referenced_widgets": [
      "22868c1785f1415fb7793d3f906f56f2",
      "855ad64e6b0a4075b4bbb6f7f28aa1a4",
      "93ae4bdb34a94fccae1f8cb742ec1c18",
      "5e531454f2df444bb54cfb4daf6e5a68",
      "36f34a91bb1548289dc816c088817514",
      "f45f210bc2a44164bdf4e3a7857d8ed9",
      "1912e1802f32431382fc309428d16855",
      "174fafb8f02d462dbc848133367464de"
     ]
    },
    "id": "d3819558",
    "outputId": "2175e97d-3460-4fd2-c7a3-bf5f1e856b3a"
   },
   "outputs": [],
   "source": [
    "print(\"Begin training.\")\n",
    "\n",
    "print_every = 500\n",
    "\n",
    "for e in tqdm(range(1, EPOCHS+1)):\n",
    "    \n",
    "    # TRAINING\n",
    "    train_epoch_loss = 0\n",
    "    train_epoch_acc = 0\n",
    "    train_epoch_f1_No_action = 0\n",
    "    train_epoch_f1_Prendi = 0\n",
    "    train_epoch_f1_Rilascia = 0\n",
    "    train_epoch_f1_Premi = 0\n",
    "    train_pred_lab = []\n",
    "    train_true_lab = []\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    hidden_train = None\n",
    "    \n",
    "    for X_train_batch, y_train_batch in train_loader:\n",
    "        X_train_batch, y_train_batch = X_train_batch.to(device), y_train_batch.to(device)\n",
    "        y_train_batch = torch.squeeze(y_train_batch)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_train_pred, _ = model(X_train_batch, hidden_train)\n",
    "        \n",
    "        #h0, c0 = hidden_train\n",
    "        #h0.detach_(), c0.detach_()\n",
    "        #hidden_train = (h0, c0)\n",
    "        \n",
    "        train_loss = criterion(y_train_pred, y_train_batch)\n",
    "        train_pred_lab.append(y_train_pred)\n",
    "        train_true_lab.append(y_train_batch)\n",
    "        \n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "                \n",
    "        train_epoch_loss += train_loss.item()\n",
    "        \n",
    "    y_pred_tags = []\n",
    "    y_true_tags = []\n",
    "    for (p, t) in zip(train_pred_lab, train_true_lab):\n",
    "        _, y_tags = torch.max(p, dim = 1)\n",
    "        y_pred_tags.extend(y_tags.tolist())\n",
    "        y_true_tags.extend(t.tolist())\n",
    "    \n",
    "    train_acc = accuracy(y_pred_tags, y_true_tags)\n",
    "    train_f1 = f1_s(y_pred_tags, y_true_tags)\n",
    "    \n",
    "    train_epoch_acc += train_acc.item()\n",
    "    train_epoch_f1_No_action += train_f1[0].item()\n",
    "    train_epoch_f1_Prendi += train_f1[1].item()\n",
    "    train_epoch_f1_Rilascia += train_f1[2].item()\n",
    "    train_epoch_f1_Premi += train_f1[3].item()\n",
    "        \n",
    "    if e % print_every == 0:\n",
    "        \n",
    "        # VALIDATION    \n",
    "        with torch.no_grad():\n",
    "\n",
    "            val_epoch_loss = 0\n",
    "            val_epoch_acc = 0\n",
    "            val_epoch_f1 = 0\n",
    "            val_epoch_f1_No_action = 0\n",
    "            val_epoch_f1_Prendi = 0\n",
    "            val_epoch_f1_Rilascia = 0\n",
    "            val_epoch_f1_Premi = 0\n",
    "            val_pred_lab = []\n",
    "            val_true_lab = []\n",
    "\n",
    "            #hidden_valid = (h0, c0)\n",
    "            hidden_valid = None\n",
    "\n",
    "            model.eval()\n",
    "            for X_val_batch, y_val_batch in val_loader:\n",
    "                X_val_batch, y_val_batch = X_val_batch.to(device), y_val_batch.to(device)\n",
    "\n",
    "                y_val_pred, _ = model(X_val_batch, hidden_valid)\n",
    "\n",
    "                val_loss = criterion(y_val_pred, y_val_batch[0][0])\n",
    "                val_pred_lab.append(y_val_pred)\n",
    "                val_true_lab.append(y_val_batch[0][0])\n",
    "                \n",
    "                val_epoch_loss += val_loss.item()\n",
    "                \n",
    "            y_pred_tags = []\n",
    "            y_true_tags = []\n",
    "            for (p, t) in zip(val_pred_lab, val_true_lab):\n",
    "                _, y_tags = torch.max(p, dim = 1)\n",
    "                y_pred_tags.extend(y_tags.tolist())\n",
    "                y_true_tags.extend(t.tolist())\n",
    "                \n",
    "            val_acc = accuracy(y_pred_tags, y_true_tags)\n",
    "            val_f1 = f1_s(y_pred_tags, y_true_tags)\n",
    "\n",
    "            val_epoch_acc += val_acc.item()\n",
    "            val_epoch_f1_No_action += val_f1[0].item()\n",
    "            val_epoch_f1_Prendi += val_f1[1].item()\n",
    "            val_epoch_f1_Rilascia += val_f1[2].item()\n",
    "            val_epoch_f1_Premi += val_f1[3].item()\n",
    "\n",
    "        loss_stats['train'].append(train_epoch_loss/len(train_loader))        \n",
    "        loss_stats['val'].append(val_epoch_loss/len(val_loader))\n",
    "        accuracy_stats['train'].append(train_epoch_acc)\n",
    "        accuracy_stats['val'].append(val_epoch_acc)\n",
    "        f1_score_No_action['train'].append(train_epoch_f1_No_action)\n",
    "        f1_score_No_action['val'].append(val_epoch_f1_No_action)\n",
    "        f1_score_Prendi['train'].append(train_epoch_f1_Prendi)\n",
    "        f1_score_Prendi['val'].append(val_epoch_f1_Prendi)\n",
    "        f1_score_Rilascia['train'].append(train_epoch_f1_Rilascia)\n",
    "        f1_score_Rilascia['val'].append(val_epoch_f1_Rilascia)\n",
    "        f1_score_Premi['train'].append(train_epoch_f1_Premi)\n",
    "        f1_score_Premi['val'].append(val_epoch_f1_Premi)\n",
    "\n",
    "        writer.add_scalars(\"Loss/train_val\", {\n",
    "            \"train\": train_epoch_loss/len(train_loader),\n",
    "            \"val\": val_epoch_loss/len(val_loader),\n",
    "        }, e)\n",
    "        writer.add_scalars(\"Acc/train_val\", {\n",
    "            \"train\": train_epoch_acc,\n",
    "            \"val\": val_epoch_acc,\n",
    "        }, e)\n",
    "        writer.add_scalars(\"F1-No_action/train_val\", {\n",
    "            \"train\": train_epoch_f1_No_action,\n",
    "            \"val\": val_epoch_f1_No_action,\n",
    "        }, e)\n",
    "        writer.add_scalars(\"F1-Prendi/train_val\", {\n",
    "            \"train\": train_epoch_f1_Prendi,\n",
    "            \"val\": val_epoch_f1_Prendi,\n",
    "        }, e)\n",
    "        writer.add_scalars(\"F1-Rilascia/train_val\", {\n",
    "            \"train\": train_epoch_f1_Rilascia,\n",
    "            \"val\": val_epoch_f1_Rilascia,\n",
    "        }, e)\n",
    "        writer.add_scalars(\"F1-Premi/train_val\", {\n",
    "            \"train\": train_epoch_f1_Premi,\n",
    "            \"val\": val_epoch_f1_Premi,\n",
    "        }, e)\n",
    "        writer.flush()\n",
    "        print(f'Epoch {e+0:03}:\\\n",
    "              | Train Loss: {train_epoch_loss/len(train_loader):.5f}\\\n",
    "              | Val Loss: {val_epoch_loss/len(val_loader):.5f}\\\n",
    "              | Train Acc: {train_epoch_acc:.3f}\\\n",
    "              | Val Acc: {val_epoch_acc:.3f}\\\n",
    "              | Train F1-No_action: {train_epoch_f1_No_action:.5f}\\\n",
    "              | Val F1-No_action: {val_epoch_f1_No_action:.5f}\\\n",
    "              | Train F1-Prendi: {train_epoch_f1_Prendi:.5f}\\\n",
    "              | Val F1-Prendi: {val_epoch_f1_Prendi:.5f}\\\n",
    "              | Train F1-Rilascia: {train_epoch_f1_Rilascia:.5f}\\\n",
    "              | Val F1-Rilascia: {val_epoch_f1_Rilascia:.5f}\\\n",
    "              | Train F1-Premi: {train_epoch_f1_Premi:.5f}\\\n",
    "              | Val F1-Premi: {val_epoch_f1_Premi:.5f}')\n",
    "writer.close()\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf53d3eb",
   "metadata": {
    "id": "bf53d3eb"
   },
   "source": [
    "## Visualizzazione Loss e Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21362aee",
   "metadata": {
    "id": "21362aee"
   },
   "source": [
    "Per tracciare i grafici delle linee di perdita e accuratezza, creiamo nuovamente un dataframe dai dizionari precision_stats e loss_stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42f2836",
   "metadata": {
    "id": "d42f2836"
   },
   "outputs": [],
   "source": [
    "# Create dataframes\n",
    "train_val_acc_df = pd.DataFrame.from_dict(accuracy_stats).reset_index().melt(id_vars=['index']).rename(columns={\"index\":\"epochs\"})\n",
    "train_val_loss_df = pd.DataFrame.from_dict(loss_stats).reset_index().melt(id_vars=['index']).rename(columns={\"index\":\"epochs\"})\n",
    "train_val_f1_No_action = pd.DataFrame.from_dict(f1_score_No_action).reset_index().melt(id_vars=['index']).rename(columns={\"index\":\"epochs\"})\n",
    "train_val_f1_Prendi = pd.DataFrame.from_dict(f1_score_Prendi).reset_index().melt(id_vars=['index']).rename(columns={\"index\":\"epochs\"})\n",
    "train_val_f1_Rilascia = pd.DataFrame.from_dict(f1_score_Rilascia).reset_index().melt(id_vars=['index']).rename(columns={\"index\":\"epochs\"})\n",
    "train_val_f1_Premi = pd.DataFrame.from_dict(f1_score_Premi).reset_index().melt(id_vars=['index']).rename(columns={\"index\":\"epochs\"})\n",
    "\n",
    "# Plot the dataframes\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20,7))\n",
    "\n",
    "sns.lineplot(data=train_val_acc_df, x = \"epochs\", y=\"value\", hue=\"variable\", ax=axes[0]).set_title('Train-Val Accuracy/Epoch')\n",
    "sns.lineplot(data=train_val_loss_df, x = \"epochs\", y=\"value\", hue=\"variable\", ax=axes[1]).set_title('Train-Val Loss/Epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BXoi7gM63d_X",
   "metadata": {
    "id": "BXoi7gM63d_X"
   },
   "outputs": [],
   "source": [
    "# Plot the dataframes\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20,7))\n",
    "\n",
    "sns.lineplot(data=train_val_f1_No_action, x = \"epochs\", y=\"value\", hue=\"variable\", ax=axes[0]).set_title('Train-Val F1-No_action/Epoch')\n",
    "sns.lineplot(data=train_val_f1_Prendi, x = \"epochs\", y=\"value\", hue=\"variable\", ax=axes[1]).set_title('Train-Val F1-Prendi/Epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZOfSJCpy3ed6",
   "metadata": {
    "id": "ZOfSJCpy3ed6"
   },
   "outputs": [],
   "source": [
    "# Plot the dataframes\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20,7))\n",
    "\n",
    "sns.lineplot(data=train_val_f1_Rilascia, x = \"epochs\", y=\"value\", hue=\"variable\", ax=axes[0]).set_title('Train-Val F1-Rilascia/Epoch')\n",
    "sns.lineplot(data=train_val_f1_Premi, x = \"epochs\", y=\"value\", hue=\"variable\", ax=axes[1]).set_title('Train-Val F1-Premi/Epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac0b337",
   "metadata": {
    "id": "bac0b337"
   },
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84238398",
   "metadata": {
    "id": "84238398"
   },
   "source": [
    "Al termine dell'addestramento, dobbiamo testare come si è comportato il nostro modello.  Nota che abbiamo usato model.eval() prima di eseguire il nostro codice di test.  Per dire a PyTorch che non vogliamo eseguire la retropropagazione durante l'inferenza, usiamo torch.no_grad(), proprio come abbiamo fatto per il ciclo di convalida sopra."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f0fd7f",
   "metadata": {
    "id": "d2f0fd7f"
   },
   "source": [
    "Iniziamo definendo un elenco che conterrà le nostre previsioni.  Quindi eseguiamo il ciclo dei nostri batch utilizzando test_loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286e2731",
   "metadata": {
    "id": "286e2731"
   },
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "y_true_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred, _ = model(X_batch)\n",
    "        guess, guess_i = categoryFromOutput(y_test_pred)\n",
    "        y_pred_list.append(guess_i)\n",
    "        y_true_list.append(y_batch[0][0].tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67a1234",
   "metadata": {
    "id": "b67a1234"
   },
   "outputs": [],
   "source": [
    "len(y_pred_list) == len(y_true_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff82a6a",
   "metadata": {
    "id": "9ff82a6a"
   },
   "outputs": [],
   "source": [
    "Y_t = y_true_list\n",
    "Y_p = y_pred_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5507ef3",
   "metadata": {
    "id": "a5507ef3"
   },
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3aa387",
   "metadata": {
    "id": "8a3aa387"
   },
   "source": [
    "Creiamo un dataframe dalla matrice di confusione e lo tracciamo come una mappa di calore utilizzando la libreria Seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1bfae3",
   "metadata": {
    "id": "6a1bfae3"
   },
   "outputs": [],
   "source": [
    "confusion_matrix_df = pd.DataFrame(confusion_matrix(y_true_list, y_pred_list, normalize='true')).rename(columns=idx2class, index=idx2class)\n",
    "sns.heatmap(confusion_matrix_df, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b39741",
   "metadata": {
    "id": "94b39741"
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_true_list, y_pred_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef57b5c",
   "metadata": {
    "id": "8ef57b5c"
   },
   "outputs": [],
   "source": [
    "class2idx = {\n",
    "    \"No_action\": 0,\n",
    "    \"Action\": 1\n",
    "}\n",
    "\n",
    "idx2class = {v: k for k, v in class2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e992ab",
   "metadata": {
    "id": "97e992ab"
   },
   "outputs": [],
   "source": [
    "real2class = {\n",
    "    0:0,\n",
    "    1:1,\n",
    "    2:1,\n",
    "    3:1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e6eb93",
   "metadata": {
    "id": "e2e6eb93"
   },
   "outputs": [],
   "source": [
    "y_pred_list = [(real2class[c]) for c in Y_p]\n",
    "y_true_list = [(real2class[c]) for c in Y_t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8da85c",
   "metadata": {
    "id": "9f8da85c"
   },
   "outputs": [],
   "source": [
    "confusion_matrix_df = pd.DataFrame(confusion_matrix(y_true_list, y_pred_list, normalize='true')).rename(columns=idx2class, index=idx2class)\n",
    "sns.heatmap(confusion_matrix_df, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d44863f",
   "metadata": {
    "id": "9d44863f"
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_true_list, y_pred_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49868e69",
   "metadata": {
    "id": "49868e69"
   },
   "outputs": [],
   "source": [
    "class2idx = {\n",
    "    \"No_action\": 0,\n",
    "    \"P/R\": 1,\n",
    "    \"Premi\": 2\n",
    "}\n",
    "\n",
    "idx2class = {v: k for k, v in class2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc4d3b2",
   "metadata": {
    "id": "ddc4d3b2"
   },
   "outputs": [],
   "source": [
    "real2class = {\n",
    "    0:0,\n",
    "    1:1,\n",
    "    2:1,\n",
    "    3:2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1194c2f1",
   "metadata": {
    "id": "1194c2f1"
   },
   "outputs": [],
   "source": [
    "y_pred_list = [(real2class[c]) for c in Y_p]\n",
    "y_true_list = [(real2class[c]) for c in Y_t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81855e9",
   "metadata": {
    "id": "b81855e9"
   },
   "outputs": [],
   "source": [
    "confusion_matrix_df = pd.DataFrame(confusion_matrix(y_true_list, y_pred_list, normalize='true')).rename(columns=idx2class, index=idx2class)\n",
    "sns.heatmap(confusion_matrix_df, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e05c93",
   "metadata": {
    "id": "d8e05c93"
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_true_list, y_pred_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2847e7",
   "metadata": {
    "id": "cf2847e7"
   },
   "outputs": [],
   "source": [
    "class2idx = {\n",
    "    \"No_action\": 0,\n",
    "    \"P/P\": 1,\n",
    "    \"Rilascia\": 2\n",
    "}\n",
    "\n",
    "idx2class = {v: k for k, v in class2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebe707c",
   "metadata": {
    "id": "3ebe707c"
   },
   "outputs": [],
   "source": [
    "real2class = {\n",
    "    0:0,\n",
    "    1:1,\n",
    "    2:2,\n",
    "    3:1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab540460",
   "metadata": {
    "id": "ab540460"
   },
   "outputs": [],
   "source": [
    "y_pred_list = [(real2class[c]) for c in Y_p]\n",
    "y_true_list = [(real2class[c]) for c in Y_t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed49bdf",
   "metadata": {
    "id": "9ed49bdf"
   },
   "outputs": [],
   "source": [
    "confusion_matrix_df = pd.DataFrame(confusion_matrix(y_true_list, y_pred_list, normalize='true')).rename(columns=idx2class, index=idx2class)\n",
    "sns.heatmap(confusion_matrix_df, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0b4425",
   "metadata": {
    "id": "5c0b4425"
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_true_list, y_pred_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f743ea9",
   "metadata": {
    "id": "5f743ea9"
   },
   "outputs": [],
   "source": [
    "class2idx = {\n",
    "    \"No_action\": 0,\n",
    "    \"R/P\": 1,\n",
    "    \"Prendi\": 2\n",
    "}\n",
    "\n",
    "idx2class = {v: k for k, v in class2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e13bac",
   "metadata": {
    "id": "73e13bac"
   },
   "outputs": [],
   "source": [
    "real2class = {\n",
    "    0:0,\n",
    "    1:2,\n",
    "    2:1,\n",
    "    3:1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d429b8",
   "metadata": {
    "id": "b0d429b8"
   },
   "outputs": [],
   "source": [
    "y_pred_list = [(real2class[c]) for c in Y_p]\n",
    "y_true_list = [(real2class[c]) for c in Y_t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75349317",
   "metadata": {
    "id": "75349317"
   },
   "outputs": [],
   "source": [
    "confusion_matrix_df = pd.DataFrame(confusion_matrix(y_true_list, y_pred_list, normalize='true')).rename(columns=idx2class, index=idx2class)\n",
    "sns.heatmap(confusion_matrix_df, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6384bdd",
   "metadata": {
    "id": "f6384bdd"
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_true_list, y_pred_list))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LSTM_1 - Test_set_replication_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "174fafb8f02d462dbc848133367464de": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1912e1802f32431382fc309428d16855": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "22868c1785f1415fb7793d3f906f56f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_93ae4bdb34a94fccae1f8cb742ec1c18",
       "IPY_MODEL_5e531454f2df444bb54cfb4daf6e5a68"
      ],
      "layout": "IPY_MODEL_855ad64e6b0a4075b4bbb6f7f28aa1a4"
     }
    },
    "36f34a91bb1548289dc816c088817514": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "5e531454f2df444bb54cfb4daf6e5a68": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_174fafb8f02d462dbc848133367464de",
      "placeholder": "​",
      "style": "IPY_MODEL_1912e1802f32431382fc309428d16855",
      "value": " 503/10000 [55:06&lt;20:00:19,  7.58s/it]"
     }
    },
    "855ad64e6b0a4075b4bbb6f7f28aa1a4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93ae4bdb34a94fccae1f8cb742ec1c18": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "  5%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f45f210bc2a44164bdf4e3a7857d8ed9",
      "max": 10000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_36f34a91bb1548289dc816c088817514",
      "value": 503
     }
    },
    "f45f210bc2a44164bdf4e3a7857d8ed9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
